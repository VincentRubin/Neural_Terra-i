{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63deb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "currentPath = os.getcwd()\n",
    "\n",
    "import configparser\n",
    "settings = configparser.ConfigParser()\n",
    "settings._interpolation = configparser.ExtendedInterpolation()\n",
    "settings.read(currentPath + \"/config/main_config.ini\")\n",
    "\n",
    "libs_path = settings.get('Main-Config', 'libs')\n",
    "output_path = settings.get('Main-Config', 'output_path') + \"/rotated_subset\"\n",
    "\n",
    "subsetSizeX = int(settings.get('Main-Config', 'subsetSizeX'))\n",
    "subsetSizeY = int(settings.get('Main-Config', 'subsetSizeY'))\n",
    "marginX = int(settings.get('Main-Config', 'marginX'))\n",
    "marginY = int(settings.get('Main-Config', 'marginY'))\n",
    "\n",
    "import sys\n",
    "sys.path.append(libs_path)\n",
    "\n",
    "from osgeo import gdal,ogr, osr\n",
    "gdal.UseExceptions()\n",
    "ogr.UseExceptions()\n",
    "osr.UseExceptions()\n",
    "\n",
    "import snappy\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "from snappy import GPF\n",
    "from snappy import jpy\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import math\n",
    "import shutil\n",
    "import json\n",
    "import geojson\n",
    "import random\n",
    "\n",
    "import array\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/questions/24816237/ipython-notebook-clear-cell-output-in-code\n",
    "from IPython.display import clear_output\n",
    "\n",
    "outFormat = 'ESRI Shapefile'\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')\n",
    "\n",
    "System = jpy.get_type('java.lang.System')\n",
    "System.gc()\n",
    "\n",
    "PrintWriterProgressMonitor = jpy.get_type('com.bc.ceres.core.PrintWriterProgressMonitor')\n",
    "FileOutputStream = jpy.get_type('java.io.FileOutputStream')\n",
    "ProductData = jpy.get_type('org.esa.snap.core.datamodel.ProductData')\n",
    "Product = jpy.get_type('org.esa.snap.core.datamodel.Product')\n",
    "GeoPos = jpy.get_type('org.esa.snap.core.datamodel.GeoPos')\n",
    "PixelPos = jpy.get_type('org.esa.snap.core.datamodel.PixelPos')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from sklearn import metrics as me\n",
    "from scipy import stats\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "folderStart = \"K:/TM/data_output/subset_start\"\n",
    "folderResult = \"K:/TM/data_output/subset_rotated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c28074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductList(path, search):\n",
    "    \n",
    "    #products = []\n",
    "    products = []\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "\n",
    "    for f in files:\n",
    "        temp = np.load(f)\n",
    "        products.append(temp['arr_0'])\n",
    "        \n",
    "    return products\n",
    "    \n",
    "def getProductList2(path, search): #TEMP\n",
    "    \n",
    "    products = []\n",
    "        \n",
    "    for pathF in os.listdir(path):\n",
    "        \n",
    "        for pathF2 in os.listdir(path + \"/\" + pathF):\n",
    "        \n",
    "            if search in pathF2:\n",
    "                temp = np.load(path + \"/\" + pathF + \"/\" + pathF2)\n",
    "                products.append(temp['arr_0'])\n",
    "            \n",
    "    return products\n",
    "\n",
    "def getProductFileList(path, search):\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceData(data):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetStarts = getProductList(folderStart, '*.npz')\n",
    "Y = getProductList2(folderResult, 'VV.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subsetStarts))\n",
    "print(len(Y))\n",
    "\n",
    "print(len(subsetStarts[0]))\n",
    "print(len(subsetStarts[0][0]))\n",
    "print(len(subsetStarts[0][0][0]))\n",
    "\n",
    "print(len(Y[0]))\n",
    "print(len(Y[0][0]))\n",
    "\n",
    "print(type(subsetStarts))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for x_ in subsetStarts:\n",
    "    \n",
    "    X.append(x_[1:])\n",
    "\n",
    "del subsetStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(X[0]))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainL = X[:80000] \n",
    "Y_trainL = Y[:80000]\n",
    "\n",
    "X_testL = X[80000:100000]\n",
    "Y_testL = Y[80000:100000]\n",
    "\n",
    "del X\n",
    "del Y\n",
    "\n",
    "print(len(X_trainL))\n",
    "print(len(Y_trainL))\n",
    "print(len(X_testL))\n",
    "print(len(Y_testL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print(len(X_train[0][0]))\n",
    "print(len(X_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_train))\n",
    "print(len(Y_train[0]))\n",
    "print(len(Y_train[0][0]))\n",
    "print(len(Y_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_trainL))\n",
    "print(type(Y_trainL))\n",
    "print(type(X_testL))\n",
    "print(type(Y_testL))\n",
    "\n",
    "X_train = np.array(X_trainL)\n",
    "del X_trainL\n",
    "\n",
    "Y_train = np.array(Y_trainL)\n",
    "del Y_trainL\n",
    "\n",
    "X_test = np.array(X_testL)\n",
    "del X_testL\n",
    "\n",
    "Y_test = np.array(Y_testL)\n",
    "del Y_testL\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "print(type(X_test))\n",
    "print(type(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0][0][0][0])\n",
    "print(X_train[0][1][0][0])\n",
    "print(X_train[0][2][0][0])\n",
    "print(X_train[0][3][0][0])\n",
    "print(X_train[0][4][0][0])\n",
    "print(X_train[0][5][0][0])\n",
    "print(X_train[0][6][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1073062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.swapaxes(X_train, 1, 2)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.swapaxes(X_train, 2, 3)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "X_test = np.swapaxes(X_test, 2, 3)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0][0][0][0])\n",
    "print(X_train[0][0][0][1])\n",
    "print(X_train[0][0][0][2])\n",
    "print(X_train[0][0][0][3])\n",
    "print(X_train[0][0][0][4])\n",
    "print(X_train[0][0][0][5])\n",
    "print(X_train[0][0][0][6])\n",
    "\n",
    "print(X_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b97b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0][0][0])\n",
    "print(Y_train[0][0][1])\n",
    "print(Y_train[0][1][0])\n",
    "print(Y_train[0][54][78])\n",
    "print(Y_train[0][120][120])\n",
    "print(Y_train[0][450][40])\n",
    "print(Y_train[0][499][450])\n",
    "print(Y_train[0][120][430])\n",
    "print(Y_train[0][40][70])\n",
    "print(Y_train[0][405][60])\n",
    "print(Y_train[0][40][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b372357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(len(Y_train), 50, 50, 1).astype('float64')\n",
    "Y_test = Y_test.reshape(len(Y_test), 50, 50, 1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0][0][0])\n",
    "print(Y_train[0][0][1])\n",
    "print(Y_train[0][1][0])\n",
    "print(Y_train[0][54][78])\n",
    "print(Y_train[0][120][120])\n",
    "print(Y_train[0][450][40])\n",
    "print(Y_train[0][499][450])\n",
    "print(Y_train[0][120][430])\n",
    "print(Y_train[0][40][70])\n",
    "print(Y_train[0][405][60])\n",
    "print(Y_train[0][40][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_max = np.amax(Y_train)\n",
    "Y_train_min = np.amin(Y_train)\n",
    "\n",
    "print(Y_train_max)\n",
    "print(Y_train_min)\n",
    "\n",
    "Y_train = (Y_train - Y_train_min) / (Y_train_max - Y_train_min + 0.00000001)\n",
    "\n",
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04caa40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#l0 = Input(shape=(height, width, 9), name='l0')\n",
    "\n",
    "#l0 = Input(shape=(len(subsetResults[0]), len(subsetResults[0][0]), 7), name='l0')\n",
    "\n",
    "l0 = Input(shape=(50, 50, 7), name='l0')\n",
    "l0_n = BatchNormalization()(l0)\n",
    "\n",
    "l1 = Conv2D(7, (5, 5), padding='same', activation='relu', name='l1')(l0_n)\n",
    "l1_mp = MaxPooling2D((2, 2), name='l1_mp')(l1)\n",
    "\n",
    "l2 = Conv2D(7, (3, 3), padding='same', activation='relu', name='l2')(l1_mp)\n",
    "#l2_mp = MaxPooling2D((5, 5), name='l2_mp')(l2)\n",
    "\n",
    "#l22 = Conv2D(14, (5, 5), padding='same', activation='relu', name='l22')(l2)\n",
    "\n",
    "l3 = Conv2D(7, (5, 5), padding='same', activation='relu', name='l3')(l2)\n",
    "l3_us = UpSampling2D((2, 2))(l3)\n",
    "\n",
    "l4 = Conv2D(1, (5, 5), padding='same', activation='relu', name='l4')(l3_us)\n",
    "l4_us = UpSampling2D((2, 2))(l4)\n",
    "\n",
    "l45 = Conv2D(1, (3, 3), padding='same', activation='relu', name='l45')(l4_us)\n",
    "l45_mp = MaxPooling2D(pool_size=(2, 2), name='l45_mp')(l45)\n",
    "\n",
    "l5 = Conv2D(1, (5, 5), padding='same', activation='relu', name='l5')(l45_mp)\n",
    "\n",
    "#flat = Flatten(name='flat')(l4_us)\n",
    "\n",
    "#l5 = Dense((250, 250), activation='relu', name='l5')(flat)\n",
    "\n",
    "#l5 = Dense(n_classes, activation='softmax', name='l5')(l4)\n",
    "\n",
    "model = Model(inputs=l0, outputs=l5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d85979",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "n_epoch = 100\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='RMSprop', metrics=['mean_absolute_percentage_error'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[0]\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp = np.swapaxes(temp, 1, 2)\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp = np.swapaxes(temp, 0, 1)\n",
    "\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86de18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in temp:\n",
    "    \n",
    "    print(np.amin(band))\n",
    "    print(np.amax(band))\n",
    "    print(\"--------------\")\n",
    "\n",
    "tempR = temp.reshape(7, 250000).astype('float64')\n",
    "    \n",
    "bins = []\n",
    "step = 0.01\n",
    "\n",
    "for i in range(0, 55):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(tempR[0])  # arguments are passed to np.histogram\n",
    "plt.title(\"X_train[0][0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37437575",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_train[0]\n",
    "\n",
    "temp = temp.reshape(250000).astype('float64')\n",
    "\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))\n",
    "\n",
    "bins = []\n",
    "step = 0.02\n",
    "\n",
    "for i in range(0, 45):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(temp, bins=bins)  # arguments are passed to np.histogram\n",
    "plt.title(\"Y_train[0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Min diff\n",
    "\n",
    "temp = Y_train[0]\n",
    "temp = temp.reshape(250000).astype('float64')\n",
    "\n",
    "minDiff = np.amax(temp)\n",
    "\n",
    "for i in range(1, len(temp)):\n",
    "    \n",
    "    tempDiff = abs(temp[i - 1] - temp[i])\n",
    "    \n",
    "    if tempDiff != 0 and tempDiff < minDiff :\n",
    "        minDiff = tempDiff\n",
    "        \n",
    "print(minDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1687996",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_train\n",
    "temp = temp.reshape(150000000).astype('float64')\n",
    "\n",
    "print(np.amax(temp))\n",
    "\n",
    "bins = []\n",
    "step = 0.02\n",
    "\n",
    "for i in range(0, 45):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(temp, bins=bins)  # arguments are passed to np.histogram\n",
    "plt.title(\"Y_train[0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63deb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp[1])\n",
    "print(type(temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33179f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.round(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21332cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f55167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
