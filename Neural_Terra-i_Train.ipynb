{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63deb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "currentPath = os.getcwd()\n",
    "\n",
    "import configparser\n",
    "settings = configparser.ConfigParser()\n",
    "settings._interpolation = configparser.ExtendedInterpolation()\n",
    "settings.read(currentPath + \"/config/main_config.ini\")\n",
    "\n",
    "output_path = settings.get('Main-Config', 'output_path') + \"/rotated_subset_ot\"\n",
    "\n",
    "subsetSizeX = int(settings.get('Main-Config', 'subsetSizeX'))\n",
    "subsetSizeY = int(settings.get('Main-Config', 'subsetSizeY'))\n",
    "marginX = int(settings.get('Main-Config', 'marginX'))\n",
    "marginY = int(settings.get('Main-Config', 'marginY'))\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Reshape\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, SeparableConv2D\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from sklearn import metrics as me\n",
    "from scipy import stats\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "folderStart = \"K:/TM/data_output/subset_start_ot\"\n",
    "folderResult = \"K:/TM/data_output/subset_rotated_ot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c28074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductList(path, search, permutations):\n",
    "    \n",
    "    #products = []\n",
    "    products = []\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for index in permutations:\n",
    "        temp = np.load(files[index])\n",
    "        products.append(temp['arr_0'])\n",
    "        \n",
    "        if i < 5:\n",
    "            print(files[index])\n",
    "            i += 1\n",
    "        \n",
    "    return products\n",
    "    \n",
    "def getProductList2(path, search, permutations): #TEMP\n",
    "    \n",
    "    products = []\n",
    "    \n",
    "    folders = os.listdir(path)\n",
    "        \n",
    "    i = 0\n",
    "        \n",
    "    for index in permutations:\n",
    "        \n",
    "        if i < 5:\n",
    "            print(folders[index])\n",
    "            i += 1\n",
    "        \n",
    "        pathF = folders[index]\n",
    "        \n",
    "        for pathF2 in os.listdir(path + \"/\" + pathF):\n",
    "        \n",
    "            if search in pathF2:\n",
    "                temp = np.load(path + \"/\" + pathF + \"/\" + pathF2)\n",
    "                products.append(temp['arr_0'])\n",
    "            \n",
    "    return products\n",
    "\n",
    "def getIndicesPermutation(path, search):\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "    \n",
    "    p = np.random.permutation(len(files))\n",
    "    \n",
    "    return p\n",
    "\n",
    "def getProductFileList(path, search):\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c467209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceData(data):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed3ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:/TM/data_output/subset_start_ot\\S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_481_293.npz\n",
      "K:/TM/data_output/subset_start_ot\\S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_479_122.npz\n",
      "K:/TM/data_output/subset_start_ot\\S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_465_263.npz\n",
      "K:/TM/data_output/subset_start_ot\\S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_489_290.npz\n",
      "K:/TM/data_output/subset_start_ot\\S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_462_27.npz\n",
      "S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_481_293\n",
      "S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_479_122\n",
      "S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_465_263\n",
      "S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_489_290\n",
      "S1A_IW_GRDH_1SDV_20210826T101413_20210826T101438_039399_04A776_7B55_462_27\n"
     ]
    }
   ],
   "source": [
    "p = getIndicesPermutation(folderStart, '*.npz')\n",
    "\n",
    "subsetStarts = getProductList(folderStart, '*.npz', p)\n",
    "Y = getProductList2(folderResult, 'VV.npz', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subsetStarts))\n",
    "print(len(Y))\n",
    "\n",
    "print(len(subsetStarts[0]))\n",
    "print(len(subsetStarts[0][0]))\n",
    "print(len(subsetStarts[0][0][0]))\n",
    "\n",
    "print(len(Y[0]))\n",
    "print(len(Y[0][0]))\n",
    "\n",
    "print(type(subsetStarts))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfb6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for x_ in subsetStarts:\n",
    "    \n",
    "    X.append(x_[1:])\n",
    "\n",
    "del subsetStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(X[0]))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46d6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "X_trainL = X[:5000] \n",
    "Y_trainL = Y[:5000]\n",
    "\n",
    "X_testL = X[5000:7000]\n",
    "Y_testL = Y[5000:7000]\n",
    "\n",
    "del X\n",
    "del Y\n",
    "\n",
    "print(len(X_trainL))\n",
    "print(len(Y_trainL))\n",
    "print(len(X_testL))\n",
    "print(len(Y_testL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print(len(X_train[0][0]))\n",
    "print(len(X_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_train))\n",
    "print(len(Y_train[0]))\n",
    "print(len(Y_train[0][0]))\n",
    "print(len(Y_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1a5abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_trainL))\n",
    "print(type(Y_trainL))\n",
    "print(type(X_testL))\n",
    "print(type(Y_testL))\n",
    "\n",
    "X_train = np.array(X_trainL)\n",
    "del X_trainL\n",
    "\n",
    "Y_train = np.array(Y_trainL)\n",
    "del Y_trainL\n",
    "\n",
    "X_test = np.array(X_testL)\n",
    "del X_testL\n",
    "\n",
    "Y_test = np.array(Y_testL)\n",
    "del Y_testL\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "print(type(X_test))\n",
    "print(type(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0][0][0][0])\n",
    "print(X_train[0][1][0][0])\n",
    "print(X_train[0][2][0][0])\n",
    "print(X_train[0][3][0][0])\n",
    "print(X_train[0][4][0][0])\n",
    "print(X_train[0][5][0][0])\n",
    "print(X_train[0][6][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1073062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 7, 50, 50)\n",
      "(5000, 50, 7, 50)\n",
      "(5000, 50, 50, 7)\n",
      "(2000, 50, 50, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.swapaxes(X_train, 1, 2)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.swapaxes(X_train, 2, 3)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "X_test = np.swapaxes(X_test, 2, 3)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0][0][0][0])\n",
    "print(X_train[0][0][0][1])\n",
    "print(X_train[0][0][0][2])\n",
    "print(X_train[0][0][0][3])\n",
    "print(X_train[0][0][0][4])\n",
    "print(X_train[0][0][0][5])\n",
    "print(X_train[0][0][0][6])\n",
    "\n",
    "print(X_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b97b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0][0][0])\n",
    "print(Y_train[0][0][1])\n",
    "print(Y_train[0][1][0])\n",
    "print(Y_train[0][54][78])\n",
    "print(Y_train[0][120][120])\n",
    "print(Y_train[0][450][40])\n",
    "print(Y_train[0][499][450])\n",
    "print(Y_train[0][120][430])\n",
    "print(Y_train[0][40][70])\n",
    "print(Y_train[0][405][60])\n",
    "print(Y_train[0][40][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de710167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_train))\n",
    "print(len(Y_train[0]))\n",
    "print(len(Y_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b372357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(len(Y_train), len(Y_train[0]), len(Y_train[0][0]), 1).astype('float32')\n",
    "Y_test = Y_test.reshape(len(Y_test), len(Y_test[0]), len(Y_test[0][0]), 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0][0][0])\n",
    "print(Y_train[0][0][1])\n",
    "print(Y_train[0][1][0])\n",
    "print(Y_train[0][54][78])\n",
    "print(Y_train[0][120][120])\n",
    "print(Y_train[0][450][40])\n",
    "print(Y_train[0][499][450])\n",
    "print(Y_train[0][120][430])\n",
    "print(Y_train[0][40][70])\n",
    "print(Y_train[0][405][60])\n",
    "print(Y_train[0][40][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_max = np.amax(Y_train)\n",
    "Y_train_min = np.amin(Y_train)\n",
    "\n",
    "print(Y_train_max)\n",
    "print(Y_train_min)\n",
    "\n",
    "Y_train = (Y_train - Y_train_min) / (Y_train_max - Y_train_min + 0.00000001)\n",
    "\n",
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace846eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "\n",
    "#l0 = Input(shape=(height, width, 9), name='l0')\n",
    "\n",
    "#l0 = Input(shape=(len(subsetResults[0]), len(subsetResults[0][0]), 7), name='l0')\n",
    "\n",
    "l0 = Input(shape=(50, 50, 7), name='l0')\n",
    "l0_n = BatchNormalization()(l0)\n",
    "\n",
    "l1 = Conv2D(7, (5, 5), padding='same', activation='relu', name='l1')(l0_n)\n",
    "l1_mp = MaxPooling2D((2, 2), name='l1_mp')(l1)\n",
    "\n",
    "l2 = Conv2D(7, (3, 3), padding='same', activation='relu', name='l2')(l1_mp)\n",
    "#l2_mp = MaxPooling2D((5, 5), name='l2_mp')(l2)\n",
    "\n",
    "#l22 = Conv2D(14, (5, 5), padding='same', activation='relu', name='l22')(l2)\n",
    "\n",
    "l3 = Conv2D(7, (5, 5), padding='same', activation='relu', name='l3')(l2)\n",
    "l3_us = UpSampling2D((2, 2))(l3)\n",
    "\n",
    "l4 = Conv2D(1, (5, 5), padding='same', activation='relu', name='l4')(l3_us)\n",
    "l4_us = UpSampling2D((2, 2))(l4)\n",
    "\n",
    "l45 = Conv2D(1, (3, 3), padding='same', activation='relu', name='l45')(l4_us)\n",
    "l45_mp = MaxPooling2D(pool_size=(2, 2), name='l45_mp')(l45)\n",
    "\n",
    "l5 = Conv2D(1, (5, 5), padding='same', activation='relu', name='l5')(l45_mp)\n",
    "\n",
    "#flat = Flatten(name='flat')(l4_us)\n",
    "\n",
    "#l5 = Dense((250, 250), activation='relu', name='l5')(flat)\n",
    "\n",
    "#l5 = Dense(n_classes, activation='softmax', name='l5')(l4)\n",
    "\n",
    "model = Model(inputs=l0, outputs=l5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca5a7601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3313: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "l0 (InputLayer)              (None, 50, 50, 7)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50, 50, 7)         28        \n",
      "_________________________________________________________________\n",
      "l1 (Conv2D)                  (None, 50, 50, 7)         1232      \n",
      "_________________________________________________________________\n",
      "l2 (Conv2D)                  (None, 50, 50, 7)         448       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 54, 54, 7)         0         \n",
      "_________________________________________________________________\n",
      "l3 (LocallyConnected2D)      (None, 50, 50, 14)        6160000   \n",
      "_________________________________________________________________\n",
      "l4 (Conv2D)                  (None, 50, 50, 7)         889       \n",
      "_________________________________________________________________\n",
      "l5 (Conv2D)                  (None, 50, 50, 14)        896       \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 54, 54, 14)        0         \n",
      "_________________________________________________________________\n",
      "l6 (LocallyConnected2D)      (None, 50, 50, 7)         6142500   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 52, 52, 7)         0         \n",
      "_________________________________________________________________\n",
      "l7 (LocallyConnected2D)      (None, 50, 50, 1)         160000    \n",
      "=================================================================\n",
      "Total params: 12,465,993\n",
      "Trainable params: 12,465,979\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# OTHER\n",
    "\n",
    "l0 = Input(shape=(50, 50, 7), name='l0')\n",
    "l0_n = BatchNormalization()(l0)\n",
    "\n",
    "l1 = Conv2D(7, (5, 5), padding='same', activation='tanh', name='l1')(l0_n)\n",
    "\n",
    "l2 = Conv2D(7, (3, 3), padding='same', activation='relu', name='l2')(l1)\n",
    "l2_pad = layers.ZeroPadding2D(padding=(2, 2))(l2)\n",
    "\n",
    "l3 = layers.LocallyConnected2D(14, (5, 5), activation='relu', name='l3')(l2_pad)\n",
    "\n",
    "l4 = Conv2D(7, (3, 3), padding='same', activation='selu', name='l4')(l3)\n",
    "\n",
    "l5 = Conv2D(14, (3, 3), padding='same', activation='softmax', name='l5')(l4)\n",
    "l5_pad = layers.ZeroPadding2D(padding=(2, 2))(l5)\n",
    "\n",
    "l6 = layers.LocallyConnected2D(7, (5, 5), activation='relu', name='l6')(l5_pad)\n",
    "l6_pad = layers.ZeroPadding2D(padding=(1, 1))(l6)\n",
    "\n",
    "l7 = layers.LocallyConnected2D(1, (3, 3), activation='relu', name='l7')(l6_pad)\n",
    "\n",
    "model = Model(inputs=l0, outputs=l7)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04caa40c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ede587eb90e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0ml2_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0ml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLocallyConnected2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml2_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0ml4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'selu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\layers\\local.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    364\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m                                 self.data_format)\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mlocal_conv2d\u001b[1;34m(inputs, kernel, kernel_size, strides, output_shape, data_format)\u001b[0m\n\u001b[0;32m   4223\u001b[0m                                   (1, -1, feature_dim)))\n\u001b[0;32m   4224\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4225\u001b[1;33m                 xs.append(reshape(inputs[:, slice_row, slice_col, :],\n\u001b[0m\u001b[0;32m   4226\u001b[0m                                   (1, -1, feature_dim)))\n\u001b[0;32m   4227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m    653\u001b[0m                       [tensor] + begin + end + strides) as name:\n\u001b[0;32m    654\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[0;32m    656\u001b[0m                                                   stack(strides))\n\u001b[0;32m    657\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       \u001b[1;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1035\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1036\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Input list contains non-constant tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[0;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[0;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[1;32m-> 1087\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    303\u001b[0m                                          as_ref=False):\n\u001b[0;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    244\u001b[0m   \"\"\"\n\u001b[0;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 246\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    288\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[0;32m    289\u001b[0m              \"dtype\": dtype_value},\n\u001b[1;32m--> 290\u001b[1;33m       name=name).outputs[0]\n\u001b[0m\u001b[0;32m    291\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3616\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3618\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 2027\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1859\u001b[0m     \u001b[1;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m     \u001b[1;31m# It might be worth creating a convenient way to re-use the same status.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m     \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_SetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l0 = Input(shape=(50, 50, 7), name='l0')\n",
    "l0_n = BatchNormalization()(l0)\n",
    "\n",
    "l1 = Conv2D(14, (5, 5), padding='same', activation='tanh', name='l1')(l0_n)\n",
    "\n",
    "l2 = Conv2D(28, (3, 3), padding='same', activation='relu', name='l2')(l1)\n",
    "l2_pad = layers.ZeroPadding2D(padding=(2, 2))(l2)\n",
    "\n",
    "l3 = layers.LocallyConnected2D(28, (5, 5), activation='relu', name='l3')(l2_pad)\n",
    "\n",
    "l4 = Conv2D(14, (3, 3), padding='same', activation='selu', name='l4')(l3)\n",
    "\n",
    "l5 = Conv2D(7, (3, 3), padding='same', activation='softmax', name='l5')(l4)\n",
    "l5_pad = layers.ZeroPadding2D(padding=(1, 1))(l5)\n",
    "\n",
    "l6 = layers.LocallyConnected2D(1, (3, 3), activation='relu', name='l6')(l5_pad)\n",
    "\n",
    "model = Model(inputs=l0, outputs=l6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d85979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      " 832/5000 [===>..........................] - ETA: 23:01 - loss: 67.3166 - mean_absolute_percentage_error: 67.3165"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_epoch = 100\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='RMSprop', metrics=['mean_absolute_percentage_error'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[0]\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp = np.swapaxes(temp, 1, 2)\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp = np.swapaxes(temp, 0, 1)\n",
    "\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86de18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in temp:\n",
    "    \n",
    "    print(np.amin(band))\n",
    "    print(np.amax(band))\n",
    "    print(\"--------------\")\n",
    "\n",
    "tempR = temp.reshape(7, 250000).astype('float64')\n",
    "    \n",
    "bins = []\n",
    "step = 0.01\n",
    "\n",
    "for i in range(0, 55):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(tempR[0])  # arguments are passed to np.histogram\n",
    "plt.title(\"X_train[0][0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37437575",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_train[0]\n",
    "\n",
    "temp = temp.reshape(250000).astype('float64')\n",
    "\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))\n",
    "\n",
    "bins = []\n",
    "step = 0.02\n",
    "\n",
    "for i in range(0, 45):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(temp, bins=bins)  # arguments are passed to np.histogram\n",
    "plt.title(\"Y_train[0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Min diff\n",
    "\n",
    "temp = Y_train[0]\n",
    "temp = temp.reshape(250000).astype('float64')\n",
    "\n",
    "minDiff = np.amax(temp)\n",
    "\n",
    "for i in range(1, len(temp)):\n",
    "    \n",
    "    tempDiff = abs(temp[i - 1] - temp[i])\n",
    "    \n",
    "    if tempDiff != 0 and tempDiff < minDiff :\n",
    "        minDiff = tempDiff\n",
    "        \n",
    "print(minDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1687996",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_train\n",
    "temp = temp.reshape(150000000).astype('float64')\n",
    "\n",
    "print(np.amax(temp))\n",
    "\n",
    "bins = []\n",
    "step = 0.02\n",
    "\n",
    "for i in range(0, 45):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(temp, bins=bins)  # arguments are passed to np.histogram\n",
    "plt.title(\"Y_train[0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63deb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp[1])\n",
    "print(type(temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.round(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460df707",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=3, verbose=1, validation_data=(X_test, Y_test), initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc409f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = getIndicesPermutation(folderStart, '*.npz')\n",
    "\n",
    "#for index in p:\n",
    "#    print(index)\n",
    "    \n",
    "ok = True\n",
    "    \n",
    "for i in range(12432):\n",
    "    \n",
    "    ok = ok and (i in p)\n",
    "    \n",
    "print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05c887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc368248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bca132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3d00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
