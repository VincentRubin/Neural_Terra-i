{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63deb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "currentPath = os.getcwd()\n",
    "\n",
    "import configparser\n",
    "settings = configparser.ConfigParser()\n",
    "settings._interpolation = configparser.ExtendedInterpolation()\n",
    "settings.read(currentPath + \"/config/main_config.ini\")\n",
    "\n",
    "libs_path = settings.get('Main-Config', 'libs')\n",
    "output_path = settings.get('Main-Config', 'output_path') + \"/rotated_subset\"\n",
    "\n",
    "subsetSizeX = int(settings.get('Main-Config', 'subsetSizeX'))\n",
    "subsetSizeY = int(settings.get('Main-Config', 'subsetSizeY'))\n",
    "marginX = int(settings.get('Main-Config', 'marginX'))\n",
    "marginY = int(settings.get('Main-Config', 'marginY'))\n",
    "\n",
    "import sys\n",
    "sys.path.append(libs_path)\n",
    "\n",
    "from osgeo import gdal,ogr, osr\n",
    "gdal.UseExceptions()\n",
    "ogr.UseExceptions()\n",
    "osr.UseExceptions()\n",
    "\n",
    "import snappy\n",
    "from snappy import ProductIO\n",
    "from snappy import HashMap\n",
    "from snappy import GPF\n",
    "from snappy import jpy\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import cycle\n",
    "import math\n",
    "import shutil\n",
    "import json\n",
    "import geojson\n",
    "import random\n",
    "\n",
    "import array\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://stackoverflow.com/questions/24816237/ipython-notebook-clear-cell-output-in-code\n",
    "from IPython.display import clear_output\n",
    "\n",
    "outFormat = 'ESRI Shapefile'\n",
    "\n",
    "GPF.getDefaultInstance().getOperatorSpiRegistry().loadOperatorSpis()\n",
    "HashMap = snappy.jpy.get_type('java.util.HashMap')\n",
    "\n",
    "System = jpy.get_type('java.lang.System')\n",
    "System.gc()\n",
    "\n",
    "PrintWriterProgressMonitor = jpy.get_type('com.bc.ceres.core.PrintWriterProgressMonitor')\n",
    "FileOutputStream = jpy.get_type('java.io.FileOutputStream')\n",
    "ProductData = jpy.get_type('org.esa.snap.core.datamodel.ProductData')\n",
    "Product = jpy.get_type('org.esa.snap.core.datamodel.Product')\n",
    "GeoPos = jpy.get_type('org.esa.snap.core.datamodel.GeoPos')\n",
    "PixelPos = jpy.get_type('org.esa.snap.core.datamodel.PixelPos')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "#from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Input, BatchNormalization\n",
    "from sklearn import metrics as me\n",
    "from scipy import stats\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "folderStart = \"K:/TM/data_output/subset_start\"\n",
    "folderResult = \"K:/TM/data_output/subset_rotated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c28074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProductList(path, search):\n",
    "    \n",
    "    #products = []\n",
    "    products = []\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "\n",
    "    for f in files:\n",
    "        temp = np.load(f)\n",
    "        products.append(temp['arr_0'])\n",
    "        \n",
    "    return products\n",
    "    \n",
    "def getProductList2(path, search): #TEMP\n",
    "    \n",
    "    products = []\n",
    "        \n",
    "    for pathF in os.listdir(path):\n",
    "        \n",
    "        for pathF2 in os.listdir(path + \"/\" + pathF):\n",
    "        \n",
    "            if search in pathF2:\n",
    "                temp = np.load(path + \"/\" + pathF + \"/\" + pathF2)\n",
    "                products.append(temp['arr_0'])\n",
    "            \n",
    "    return products\n",
    "\n",
    "def getProductFileList(path, search):\n",
    "    \n",
    "    lbs_input_path = os.path.join(path, search)\n",
    "    files = glob.glob(lbs_input_path)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c467209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceData(data):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed3ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetStarts = getProductList(folderStart, '*.npz')\n",
    "Y = getProductList2(folderResult, 'VV.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subsetStarts))\n",
    "print(len(Y))\n",
    "\n",
    "print(len(subsetStarts[0]))\n",
    "print(len(subsetStarts[0][0]))\n",
    "print(len(subsetStarts[0][0][0]))\n",
    "\n",
    "print(len(Y[0]))\n",
    "print(len(Y[0][0]))\n",
    "\n",
    "print(type(subsetStarts))\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfb6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for x_ in subsetStarts:\n",
    "    \n",
    "    X.append(x_[1:])\n",
    "\n",
    "del subsetStarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X))\n",
    "print(len(X[0]))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46d6006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "80000\n",
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "X_trainL = X[:80000] \n",
    "Y_trainL = Y[:80000]\n",
    "\n",
    "X_testL = X[80000:100000]\n",
    "Y_testL = Y[80000:100000]\n",
    "\n",
    "del X\n",
    "del Y\n",
    "\n",
    "print(len(X_trainL))\n",
    "print(len(Y_trainL))\n",
    "print(len(X_testL))\n",
    "print(len(Y_testL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print(len(X_train[0][0]))\n",
    "print(len(X_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_train))\n",
    "print(len(Y_train[0]))\n",
    "print(len(Y_train[0][0]))\n",
    "print(len(Y_train[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1a5abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_trainL))\n",
    "print(type(Y_trainL))\n",
    "print(type(X_testL))\n",
    "print(type(Y_testL))\n",
    "\n",
    "X_train = np.array(X_trainL)\n",
    "del X_trainL\n",
    "\n",
    "Y_train = np.array(Y_trainL)\n",
    "del Y_trainL\n",
    "\n",
    "X_test = np.array(X_testL)\n",
    "del X_testL\n",
    "\n",
    "Y_test = np.array(Y_testL)\n",
    "del Y_testL\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "print(type(X_test))\n",
    "print(type(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0][0][0][0])\n",
    "print(X_train[0][1][0][0])\n",
    "print(X_train[0][2][0][0])\n",
    "print(X_train[0][3][0][0])\n",
    "print(X_train[0][4][0][0])\n",
    "print(X_train[0][5][0][0])\n",
    "print(X_train[0][6][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1073062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 7, 50, 50)\n",
      "(80000, 50, 7, 50)\n",
      "(80000, 50, 50, 7)\n",
      "(20000, 50, 50, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.swapaxes(X_train, 1, 2)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train = np.swapaxes(X_train, 2, 3)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "X_test = np.swapaxes(X_test, 2, 3)\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0][0][0][0])\n",
    "print(X_train[0][0][0][1])\n",
    "print(X_train[0][0][0][2])\n",
    "print(X_train[0][0][0][3])\n",
    "print(X_train[0][0][0][4])\n",
    "print(X_train[0][0][0][5])\n",
    "print(X_train[0][0][0][6])\n",
    "\n",
    "print(X_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b97b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0][0][0])\n",
    "print(Y_train[0][0][1])\n",
    "print(Y_train[0][1][0])\n",
    "print(Y_train[0][54][78])\n",
    "print(Y_train[0][120][120])\n",
    "print(Y_train[0][450][40])\n",
    "print(Y_train[0][499][450])\n",
    "print(Y_train[0][120][430])\n",
    "print(Y_train[0][40][70])\n",
    "print(Y_train[0][405][60])\n",
    "print(Y_train[0][40][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b372357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(len(Y_train), 50, 50, 1).astype('float64')\n",
    "Y_test = Y_test.reshape(len(Y_test), 50, 50, 1).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train[0][0][0])\n",
    "print(Y_train[0][0][1])\n",
    "print(Y_train[0][1][0])\n",
    "print(Y_train[0][54][78])\n",
    "print(Y_train[0][120][120])\n",
    "print(Y_train[0][450][40])\n",
    "print(Y_train[0][499][450])\n",
    "print(Y_train[0][120][430])\n",
    "print(Y_train[0][40][70])\n",
    "print(Y_train[0][405][60])\n",
    "print(Y_train[0][40][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_max = np.amax(Y_train)\n",
    "Y_train_min = np.amin(Y_train)\n",
    "\n",
    "print(Y_train_max)\n",
    "print(Y_train_min)\n",
    "\n",
    "Y_train = (Y_train - Y_train_min) / (Y_train_max - Y_train_min + 0.00000001)\n",
    "\n",
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04caa40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "l0 (InputLayer)              (None, 50, 50, 7)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50, 50, 7)         28        \n",
      "_________________________________________________________________\n",
      "l1 (Conv2D)                  (None, 50, 50, 7)         1232      \n",
      "_________________________________________________________________\n",
      "l1_mp (MaxPooling2D)         (None, 25, 25, 7)         0         \n",
      "_________________________________________________________________\n",
      "l2 (Conv2D)                  (None, 25, 25, 7)         448       \n",
      "_________________________________________________________________\n",
      "l3 (Conv2D)                  (None, 25, 25, 7)         1232      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 50, 50, 7)         0         \n",
      "_________________________________________________________________\n",
      "l4 (Conv2D)                  (None, 50, 50, 1)         176       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "l45 (Conv2D)                 (None, 100, 100, 1)       10        \n",
      "_________________________________________________________________\n",
      "l45_mp (MaxPooling2D)        (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "l5 (Conv2D)                  (None, 50, 50, 1)         26        \n",
      "=================================================================\n",
      "Total params: 3,152\n",
      "Trainable params: 3,138\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#l0 = Input(shape=(height, width, 9), name='l0')\n",
    "\n",
    "#l0 = Input(shape=(len(subsetResults[0]), len(subsetResults[0][0]), 7), name='l0')\n",
    "\n",
    "l0 = Input(shape=(50, 50, 7), name='l0')\n",
    "l0_n = BatchNormalization()(l0)\n",
    "\n",
    "l1 = Conv2D(7, (5, 5), padding='same', activation='relu', name='l1')(l0_n)\n",
    "l1_mp = MaxPooling2D((2, 2), name='l1_mp')(l1)\n",
    "\n",
    "l2 = Conv2D(7, (3, 3), padding='same', activation='relu', name='l2')(l1_mp)\n",
    "#l2_mp = MaxPooling2D((5, 5), name='l2_mp')(l2)\n",
    "\n",
    "#l22 = Conv2D(14, (5, 5), padding='same', activation='relu', name='l22')(l2)\n",
    "\n",
    "l3 = Conv2D(7, (5, 5), padding='same', activation='relu', name='l3')(l2)\n",
    "l3_us = UpSampling2D((2, 2))(l3)\n",
    "\n",
    "l4 = Conv2D(1, (5, 5), padding='same', activation='relu', name='l4')(l3_us)\n",
    "l4_us = UpSampling2D((2, 2))(l4)\n",
    "\n",
    "l45 = Conv2D(1, (3, 3), padding='same', activation='relu', name='l45')(l4_us)\n",
    "l45_mp = MaxPooling2D(pool_size=(2, 2), name='l45_mp')(l45)\n",
    "\n",
    "l5 = Conv2D(1, (5, 5), padding='same', activation='relu', name='l5')(l45_mp)\n",
    "\n",
    "#flat = Flatten(name='flat')(l4_us)\n",
    "\n",
    "#l5 = Dense((250, 250), activation='relu', name='l5')(flat)\n",
    "\n",
    "#l5 = Dense(n_classes, activation='softmax', name='l5')(l4)\n",
    "\n",
    "model = Model(inputs=l0, outputs=l5)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d85979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vincent\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 392s 5ms/step - loss: 97.8939 - mean_absolute_percentage_error: 97.8939 - val_loss: 236.3965 - val_mean_absolute_percentage_error: 236.3966\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 391s 5ms/step - loss: 51.5712 - mean_absolute_percentage_error: 51.5712 - val_loss: 71.3933 - val_mean_absolute_percentage_error: 71.3933\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 390s 5ms/step - loss: 43.6593 - mean_absolute_percentage_error: 43.6593 - val_loss: 59.3625 - val_mean_absolute_percentage_error: 59.3625\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 392s 5ms/step - loss: 41.4839 - mean_absolute_percentage_error: 41.4839 - val_loss: 59.3807 - val_mean_absolute_percentage_error: 59.3807\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 391s 5ms/step - loss: 39.9419 - mean_absolute_percentage_error: 39.9419 - val_loss: 56.0188 - val_mean_absolute_percentage_error: 56.0187\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 389s 5ms/step - loss: 39.0358 - mean_absolute_percentage_error: 39.0358 - val_loss: 52.6727 - val_mean_absolute_percentage_error: 52.6727\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 388s 5ms/step - loss: 38.2402 - mean_absolute_percentage_error: 38.2402 - val_loss: 43.9581 - val_mean_absolute_percentage_error: 43.9581\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 389s 5ms/step - loss: 37.6246 - mean_absolute_percentage_error: 37.6246 - val_loss: 39.4742 - val_mean_absolute_percentage_error: 39.4742\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 388s 5ms/step - loss: 36.8182 - mean_absolute_percentage_error: 36.8182 - val_loss: 38.0359 - val_mean_absolute_percentage_error: 38.0359\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 388s 5ms/step - loss: 36.0469 - mean_absolute_percentage_error: 36.0469 - val_loss: 34.0619 - val_mean_absolute_percentage_error: 34.0619\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 388s 5ms/step - loss: 35.1544 - mean_absolute_percentage_error: 35.1544 - val_loss: 34.0261 - val_mean_absolute_percentage_error: 34.0261\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 389s 5ms/step - loss: 34.4578 - mean_absolute_percentage_error: 34.4578 - val_loss: 31.9872 - val_mean_absolute_percentage_error: 31.9872\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 410s 5ms/step - loss: 33.7187 - mean_absolute_percentage_error: 33.7187 - val_loss: 33.0535 - val_mean_absolute_percentage_error: 33.0535\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 413s 5ms/step - loss: 33.1902 - mean_absolute_percentage_error: 33.1902 - val_loss: 34.7498 - val_mean_absolute_percentage_error: 34.7498\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 409s 5ms/step - loss: 32.7839 - mean_absolute_percentage_error: 32.7838 - val_loss: 31.3718 - val_mean_absolute_percentage_error: 31.3718\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 411s 5ms/step - loss: 32.3318 - mean_absolute_percentage_error: 32.3318 - val_loss: 30.7601 - val_mean_absolute_percentage_error: 30.7601\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 412s 5ms/step - loss: 31.9626 - mean_absolute_percentage_error: 31.9626 - val_loss: 29.7824 - val_mean_absolute_percentage_error: 29.7824\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 410s 5ms/step - loss: 31.6507 - mean_absolute_percentage_error: 31.6507 - val_loss: 30.3148 - val_mean_absolute_percentage_error: 30.3148\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 411s 5ms/step - loss: 31.5064 - mean_absolute_percentage_error: 31.5064 - val_loss: 32.0752 - val_mean_absolute_percentage_error: 32.0752\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 395s 5ms/step - loss: 31.2515 - mean_absolute_percentage_error: 31.2515 - val_loss: 30.3533 - val_mean_absolute_percentage_error: 30.3533\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 380s 5ms/step - loss: 31.0868 - mean_absolute_percentage_error: 31.0868 - val_loss: 30.2217 - val_mean_absolute_percentage_error: 30.2217\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 379s 5ms/step - loss: 30.9141 - mean_absolute_percentage_error: 30.9141 - val_loss: 29.5469 - val_mean_absolute_percentage_error: 29.5469\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 377s 5ms/step - loss: 30.7376 - mean_absolute_percentage_error: 30.7376 - val_loss: 31.9322 - val_mean_absolute_percentage_error: 31.9322\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 376s 5ms/step - loss: 30.6172 - mean_absolute_percentage_error: 30.6172 - val_loss: 30.6883 - val_mean_absolute_percentage_error: 30.6883\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 376s 5ms/step - loss: 30.5552 - mean_absolute_percentage_error: 30.5552 - val_loss: 28.7154 - val_mean_absolute_percentage_error: 28.7154\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 376s 5ms/step - loss: 30.3527 - mean_absolute_percentage_error: 30.3527 - val_loss: 28.0765 - val_mean_absolute_percentage_error: 28.0765\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 376s 5ms/step - loss: 30.3375 - mean_absolute_percentage_error: 30.3375 - val_loss: 30.3174 - val_mean_absolute_percentage_error: 30.3174\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 376s 5ms/step - loss: 30.2621 - mean_absolute_percentage_error: 30.2621 - val_loss: 29.1312 - val_mean_absolute_percentage_error: 29.1312\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 382s 5ms/step - loss: 30.0478 - mean_absolute_percentage_error: 30.0478 - val_loss: 29.6153 - val_mean_absolute_percentage_error: 29.6153\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 412s 5ms/step - loss: 29.9967 - mean_absolute_percentage_error: 29.9967 - val_loss: 27.9818 - val_mean_absolute_percentage_error: 27.9818\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 418s 5ms/step - loss: 29.8957 - mean_absolute_percentage_error: 29.8957 - val_loss: 27.8774 - val_mean_absolute_percentage_error: 27.8774\n",
      "Epoch 32/100\n",
      "53248/80000 [==================>...........] - ETA: 2:19 - loss: 29.8549 - mean_absolute_percentage_error: 29.8549"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8211ad2f894b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_absolute_percentage_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'RMSprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_absolute_percentage_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\python36_\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "n_epoch = 100\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "model.compile(loss='mean_absolute_percentage_error', optimizer='RMSprop', metrics=['mean_absolute_percentage_error'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=n_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[0]\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp = np.swapaxes(temp, 1, 2)\n",
    "\n",
    "print(temp.shape)\n",
    "\n",
    "temp = np.swapaxes(temp, 0, 1)\n",
    "\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86de18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in temp:\n",
    "    \n",
    "    print(np.amin(band))\n",
    "    print(np.amax(band))\n",
    "    print(\"--------------\")\n",
    "\n",
    "tempR = temp.reshape(7, 250000).astype('float64')\n",
    "    \n",
    "bins = []\n",
    "step = 0.01\n",
    "\n",
    "for i in range(0, 55):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(tempR[0])  # arguments are passed to np.histogram\n",
    "plt.title(\"X_train[0][0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37437575",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_train[0]\n",
    "\n",
    "temp = temp.reshape(250000).astype('float64')\n",
    "\n",
    "print(np.amin(temp))\n",
    "print(np.amax(temp))\n",
    "\n",
    "bins = []\n",
    "step = 0.02\n",
    "\n",
    "for i in range(0, 45):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(temp, bins=bins)  # arguments are passed to np.histogram\n",
    "plt.title(\"Y_train[0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Min diff\n",
    "\n",
    "temp = Y_train[0]\n",
    "temp = temp.reshape(250000).astype('float64')\n",
    "\n",
    "minDiff = np.amax(temp)\n",
    "\n",
    "for i in range(1, len(temp)):\n",
    "    \n",
    "    tempDiff = abs(temp[i - 1] - temp[i])\n",
    "    \n",
    "    if tempDiff != 0 and tempDiff < minDiff :\n",
    "        minDiff = tempDiff\n",
    "        \n",
    "print(minDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1687996",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Y_train\n",
    "temp = temp.reshape(150000000).astype('float64')\n",
    "\n",
    "print(np.amax(temp))\n",
    "\n",
    "bins = []\n",
    "step = 0.02\n",
    "\n",
    "for i in range(0, 45):\n",
    "    bins.append(step * i * 1.0)\n",
    "\n",
    "plt.hist(temp, bins=bins)  # arguments are passed to np.histogram\n",
    "plt.title(\"Y_train[0] - Histogram\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63deb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp[1])\n",
    "print(type(temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.round(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(Y_train))\n",
    "print(np.amin(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Testing')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460df707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
